import streamlit as st
from streamlit_webrtc import webrtc_streamer, AudioProcessorBase, WebRtcMode
import av
import numpy as np
import tempfile
import wave
import librosa
import os

from music_buddy.audio_tools import (
    extract_chords_from_frames,
    detect_common_progressions,
    plot_chord_progression,
    analyze_lyrics
)

st.set_page_config(page_title="ðŸŽµ Music Buddy", layout="centered")
st.title(":musical_note: Music Buddy - PhÃ¢n tÃ­ch há»£p Ã¢m tá»« file Ã¢m thanh hoáº·c ghi Ã¢m trá»±c tiáº¿p")

FRAME_DURATION = 0.5

st.sidebar.header("ðŸ”¢ Chá»n cÃ¡ch nháº­p Ã¢m thanh")
mode = st.sidebar.radio("Nguá»“n Ã¢m thanh", ["Upload file WAV", "Ghi Ã¢m trá»±c tiáº¿p"])

audio_file = None
y = None
sr = None
frames_buffer = []
audio_levels = st.empty()

if mode == "Upload file WAV":
    uploaded_file = st.file_uploader("ðŸ“‚ Táº£i lÃªn file .wav", type=["wav"])
    if uploaded_file is not None:
        audio_file = uploaded_file
        y, sr = librosa.load(uploaded_file, sr=None)

elif mode == "Ghi Ã¢m trá»±c tiáº¿p":
    class AudioProcessor(AudioProcessorBase):
        def __init__(self) -> None:
            self.frames = []
            self.level = 0

        def recv_queued(self, frames):
            for frame in frames:
                pcm = frame.to_ndarray().flatten().astype(np.int16)
                self.frames.append(pcm)
                # TÃ­nh má»©c Ã¢m thanh RMS
                self.level = int(np.sqrt(np.mean(pcm**2)) / 32768 * 100)
            return frames[-1] if frames else None

    ctx = webrtc_streamer(
        key="audio",
        mode=WebRtcMode.SENDONLY,
        audio_receiver_size=1024,
        media_stream_constraints={"audio": True, "video": False},
        rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
        audio_processor_factory=AudioProcessor,
    )

    if ctx.audio_processor and ctx.state.playing:
        level = ctx.audio_processor.level
        audio_levels.progress(level if level < 100 else 99, text=f"ðŸ”Š Má»©c Ã¢m thanh: {level}%")

    if ctx.audio_processor and not ctx.state.playing:
        frames = ctx.audio_processor.frames
        if frames:
            st.success(f"âœ… ÄÃ£ ghi Ã¢m xong ({len(frames)} khá»‘i dá»¯ liá»‡u). Báº¥m 'PhÃ¢n tÃ­ch' Ä‘á»ƒ tiáº¿p tá»¥c.")
            if st.button("ðŸ“Š PhÃ¢n tÃ­ch Ã¢m thanh Ä‘Ã£ ghi"):
                audio_data = np.concatenate(frames).astype(np.int16)
                with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
                    audio_file = f.name
                    with wave.open(f, 'wb') as wf:
                        wf.setnchannels(1)
                        wf.setsampwidth(2)
                        wf.setframerate(48000)
                        wf.writeframes(audio_data.tobytes())
                y, sr = librosa.load(audio_file, sr=None)
        else:
            st.warning("âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u ghi Ã¢m. HÃ£y báº¥m Stop sau khi ghi.")

# PhÃ¢n tÃ­ch há»£p Ã¢m khi Ä‘Ã£ cÃ³ file Ã¢m thanh
if y is not None and sr is not None:
    chords = extract_chords_from_frames(y, sr, frame_duration=FRAME_DURATION)

    st.subheader("ðŸŽ¶ Chuá»—i há»£p Ã¢m:")
    st.write(" â†’ " + " - ".join(chords))

    st.subheader("ðŸ“Š Biá»ƒu Ä‘á»“ há»£p Ã¢m:")
    fig = plot_chord_progression(chords, frame_duration=FRAME_DURATION)
    st.pyplot(fig)

    st.subheader("ðŸ”€ VÃ²ng hoÃ  Ã¢m phá»• biáº¿n:")
    st.success(detect_common_progressions(chords))

    st.subheader("ðŸ“ PhÃ¢n tÃ­ch lá»i bÃ i hÃ¡t báº±ng GPT")
    lyrics = st.text_area("Nháº­p lá»i bÃ i hÃ¡t tiáº¿ng Anh hoáº·c Viá»‡t:")
    if st.button("ðŸ§ GPT phÃ¢n tÃ­ch"):
        if lyrics.strip():
            with st.spinner("Äang phÃ¢n tÃ­ch..."):
                gpt_output = analyze_lyrics(lyrics)
                st.write(gpt_output)
        else:
            st.warning("âš ï¸ Vui lÃ²ng nháº­p lá»i bÃ i hÃ¡t.")