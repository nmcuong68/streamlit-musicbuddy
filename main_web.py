import streamlit as st
from streamlit_webrtc import webrtc_streamer, AudioProcessorBase, WebRtcMode
import av
import numpy as np
import tempfile
import wave
import librosa
import os

from music_buddy.audio_tools import (
    extract_chords_from_frames,
    detect_common_progressions,
    plot_chord_progression,
    analyze_lyrics
)

st.set_page_config(page_title="üéµ Music Buddy", layout="centered")
st.title(":musical_note: Music Buddy - Ph√¢n t√≠ch h·ª£p √¢m t·ª´ file √¢m thanh ho·∫∑c ghi √¢m tr·ª±c ti·∫øp")

FRAME_DURATION = 1.0

st.sidebar.header("üî¢ Ch·ªçn c√°ch nh·∫≠p √¢m thanh")
mode = st.sidebar.radio("Ngu·ªìn √¢m thanh", ["Upload file WAV", "Ghi √¢m tr·ª±c ti·∫øp"])

audio_file = None
y = None
sr = None

if mode == "Upload file WAV":
    uploaded_file = st.file_uploader("üìÇ T·∫£i l√™n file .wav", type=["wav"])
    if uploaded_file is not None:
        audio_file = uploaded_file
        y, sr = librosa.load(uploaded_file, sr=None)

elif mode == "Ghi √¢m tr·ª±c ti·∫øp":
    class AudioProcessor(AudioProcessorBase):
        def __init__(self) -> None:
            self.frames = []

        def recv(self, frame: av.AudioFrame) -> av.AudioFrame:
            pcm = frame.to_ndarray().flatten().astype(np.int16)
            self.frames.append(pcm)
            return frame

    ctx = webrtc_streamer(
        key="audio",
        mode=WebRtcMode.SENDONLY,
        audio_receiver_size=1024,
        media_stream_constraints={"audio": True, "video": False},
        audio_processor_factory=AudioProcessor,
    )

    if ctx.audio_processor and not ctx.state.playing and ctx.audio_processor.frames:
        audio_data = np.concatenate(ctx.audio_processor.frames).astype(np.int16)
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
            audio_file = f.name
            with wave.open(f, 'wb') as wf:
                wf.setnchannels(1)
                wf.setsampwidth(2)
                wf.setframerate(48000)
                wf.writeframes(audio_data.tobytes())

        y, sr = librosa.load(audio_file, sr=None)

# Ph√¢n t√≠ch h·ª£p √¢m khi ƒë√£ c√≥ file √¢m thanh
if y is not None and sr is not None:
    chords = extract_chords_from_frames(y, sr)

    st.subheader("üé∂ Chu·ªói h·ª£p √¢m:")
    st.write(" ‚Üí " + " - ".join(chords))

    st.subheader("üìä Bi·ªÉu ƒë·ªì h·ª£p √¢m:")
    fig = plot_chord_progression(chords, frame_duration=FRAME_DURATION)
    st.pyplot(fig)

    st.subheader("üîÄ V√≤ng ho√† √¢m ph·ªï bi·∫øn:")
    st.success(detect_common_progressions(chords))

    st.subheader("üìù Ph√¢n t√≠ch l·ªùi b√†i h√°t b·∫±ng GPT")
    lyrics = st.text_area("Nh·∫≠p l·ªùi b√†i h√°t ti·∫øng Anh ho·∫∑c Vi·ªát:")
    if st.button("üßê GPT ph√¢n t√≠ch"):
        if lyrics.strip():
            with st.spinner("ƒêang ph√¢n t√≠ch..."):
                gpt_output = analyze_lyrics(lyrics)
                st.write(gpt_output)
        else:
            st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p l·ªùi b√†i h√°t.")